{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import lightgbm as lgb_model\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer \n",
    "from sklearn.model_selection import cross_val_score\n",
    "SEED=1\n",
    "data_path='/Users/yezhuoyang/Desktop/ml/p1/handout/train_shuffle.txt'\n",
    "handout_path='/Users/yezhuoyang/Desktop/ml/p1/handout/test_handout.txt'\n",
    "output_path='/Users/yezhuoyang/Desktop/ml/p1/handout/submission.csv'\n",
    "def read(path):\n",
    "    tag_list=[]\n",
    "    input_list=[]\n",
    "    with open(path,'r') as f:\n",
    "       for line in f.readlines(): \n",
    "            tag_list.append(line.split('\\t')[0].strip())\n",
    "            input_list.append(line.split('\\t')[1].strip())\n",
    "    return input_list,tag_list    \n",
    "def read_output(path):\n",
    "    input_list=[]\n",
    "    with open(path,'r') as f:\n",
    "        for line in f.readlines():\n",
    "            input_list.append(line.strip())\n",
    "    return input_list        \n",
    "def process(input_list,handout_list,tag_list,max_f=30000):\n",
    "      label_list=[]\n",
    "      data_list=[]\n",
    "      transformer = TfidfTransformer()  \n",
    "      vectorizer=CountVectorizer(min_df=1,ngram_range=(1,4),token_pattern='\\w',max_features=max_f)\n",
    "      for x in tag_list:\n",
    "         if x=='0':\n",
    "                label_list.append(0)\n",
    "         else:\n",
    "                label_list.append(1)     \n",
    "      data_list= vectorizer.fit_transform(input_list+handout_list)\n",
    "      return data_list[:len(input_list)],data_list[len(input_list):],np.array(label_list)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_handout=read_output(handout_path)\n",
    "X_origin,y_origin=read(data_path)\n",
    "X,X_handout,y=process(X_origin,X_handout,y_origin) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The underlying estimator SVC has no `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to SelectFromModel or call fit before calling transform.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-353-ca5e59855382>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSelectFromModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSelectFromModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mprefit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mX_handout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_handout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \"\"\"\n\u001b[1;32m     75\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_support\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             warn(\"No features were selected: either the data is\"\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/base.py\u001b[0m in \u001b[0;36mget_support\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[0mare\u001b[0m \u001b[0mindices\u001b[0m \u001b[0minto\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \"\"\"\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_support_mask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/from_model.py\u001b[0m in \u001b[0;36m_get_support_mask\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    151\u001b[0m                              \u001b[0;34m' \"prefit=True\" while passing the fitted'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m                              ' estimator to the constructor.')\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_feature_importances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0mthreshold\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_calculate_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_features\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/feature_selection/from_model.py\u001b[0m in \u001b[0;36m_get_feature_importances\u001b[0;34m(estimator, norm_order)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;34m\"`feature_importances_` attribute. Either pass a fitted estimator\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;34m\" to SelectFromModel or call fit before calling transform.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m             % estimator.__class__.__name__)\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimportances\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The underlying estimator SVC has no `coef_` or `feature_importances_` attribute. Either pass a fitted estimator to SelectFromModel or call fit before calling transform."
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.svm import SVC\n",
    "svc=SVC(kernel='linear',C=0.0176)\n",
    "sfm=SelectFromModel(svc,threshold=0.25)\n",
    "sfm.fit(X,y)\n",
    "X=model.transform(X)\n",
    "X_handout=model.transform(X_handout)\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=.2, random_state=SEED)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9413972 , 0.93610013, 0.9353178 , 0.93310171, 0.94185875])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoresx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def write(y_pred,path):\n",
    "    i=0\n",
    "    y_pred=list(y_pred)\n",
    "    with open(path,'w',newline='') as f:\n",
    "        csv_write=csv.writer(f)\n",
    "        csv_write.writerow(['id','pred'])\n",
    "        for x in y_pred:\n",
    "            csv_write.writerow([i,x])\n",
    "            i=i+1\n",
    "    f.close()        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(y_pred,output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "第一个voting 尝试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-183-39eaeb71a280>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'1__C'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0meclf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mscores\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcross_val_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[1;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m                                 error_score=error_score)\n\u001b[0m\u001b[1;32m    403\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'test_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[0;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m             error_score=error_score)\n\u001b[0;32m--> 240\u001b[0;31m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[1;32m    241\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    720\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults_container\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1189\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params)\u001b[0m\n\u001b[1;32m    709\u001b[0m                                \u001b[0;32mfor\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m                                in product(candidate_params,\n\u001b[0;32m--> 711\u001b[0;31m                                           cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                 \u001b[0mall_candidate_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    529\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    198\u001b[0m             delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n\u001b[1;32m    199\u001b[0m                                              sample_weight=sample_weight)\n\u001b[0;32m--> 200\u001b[0;31m             for clf in clfs if clf is not None)\n\u001b[0m\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamed_estimators_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBunch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 920\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    921\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    922\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    714\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 716\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    717\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    718\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 182\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    183\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[0;32m--> 225\u001b[0;31m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    410\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;31m# Fit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAdaBoostClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    413\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_validate_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    141\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m                 \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m                 random_state)\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m             \u001b[0;31m# Early termination\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[1;32m    471\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malgorithm\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'SAMME.R'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_boost_real\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miboost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# elif self.algorithm == \"SAMME\":\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/weight_boosting.py\u001b[0m in \u001b[0;36m_boost_real\u001b[0;34m(self, iboost, X, y, sample_weight, random_state)\u001b[0m\n\u001b[1;32m    480\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0my_predict_proba\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    799\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 801\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    802\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "clf1=SVC(C=0.0176,random_state=SEED,kernel=\"linear\",probability=True)\n",
    "clf2=MLPClassifier((80, 2),solver='lbfgs',alpha=167,early_stopping=False, random_state=SEED)\n",
    "clf3=AdaBoostClassifier(n_estimators=100,random_state=SEED)\n",
    "#clf4=RandomForestClassifier(n_estimators=100, max_features=3, random_state=SEED)#随机森林\n",
    "eclf=VotingClassifier(estimators=[('1',clf1),('2',clf2),('3',clf3)],voting='soft')\n",
    "params={'1__C':np.logspace(-1,1,20)}\n",
    "grid=GridSearchCV(estimator=eclf,param_grid=params,cv=5)\n",
    "scores=cross_val_score(grid,X[:1000],y[:1000], cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=SVC(C=0.0176,random_state=SEED,kernel=\"linear\",probability=True)\n",
    "params={'clf__C':np.logspace(-1,1,20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1=SVC(C=0.0176,random_state=SEED,kernel=\"linear\",probability=True)\n",
    "clf2=MLPClassifier((35, 2),solver='lbfgs',alpha=0.01,early_stopping=False, random_state=SEED)\n",
    "eclf=VotingClassifier(estimators=[('1',clf1),('2',clf2)],voting='soft')\n",
    "s1=cross_val_score(clf1,X[:10000],y[:10000], cv=5, scoring='roc_auc')\n",
    "s2=cross_val_score(clf2,X[:10000],y[:10000], cv=5, scoring='roc_auc')\n",
    "s3=cross_val_score(eclf,X[:10000],y[:10000], cv=5, scoring='roc_auc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "def auc(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "from keras import optimizers\n",
    "def create_model(size=512,loss='binary_crossentropy',L1=0.000,L2=0,DROPOUT=0.002154434):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(size,input_dim=X.shape[1],kernel_regularizer=regularizers.l2(L2),activity_regularizer=regularizers.l1(L1),activation='relu'))\n",
    "    model.add(Dropout(DROPOUT))\n",
    "    model.add(Dense(size,activation='relu',kernel_regularizer=regularizers.l2(L2),activity_regularizer=regularizers.l1(L1)))\n",
    "    model.add(Dense(1,activation='sigmoid'))\n",
    "    adam=optimizers.Adam()\n",
    "    model.compile(loss='binary_crossentropy',optimizer=adam, metrics=[auc])\n",
    "    return model\n",
    "from sklearn.metrics import roc_auc_score\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4213"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "16000/16000 [==============================] - 88s 5ms/step - loss: 0.6463 - auc: 0.8905\n",
      "Epoch 2/5\n",
      "16000/16000 [==============================] - 68s 4ms/step - loss: 0.4808 - auc: 0.9165\n",
      "Epoch 3/5\n",
      " 8704/16000 [===============>..............] - ETA: 31s - loss: 0.4667 - auc: 0.9209"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-216-e70f158dc852>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_handout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model=create_model(learn_rate=0.01)\n",
    "model.fit(X,y,verbose=1,epochs=5)\n",
    "y_pred=model.predict_proba(X_handout)\n",
    "y_pred=[x[0] for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/3 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2688/6400 [===========>..................] - ETA: 29s - loss: 2.8499 - auc: 0.8018"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-188-5f7b746f554f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mresult1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-188-5f7b746f554f>\u001b[0m in \u001b[0;36mtest_epoch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mB\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_size_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m         \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_MANUAL_VAR_INIT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m             \u001b[0mvariables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mglobal_variables\u001b[0;34m(scope)\u001b[0m\n\u001b[1;32m   2715\u001b[0m     \u001b[0mA\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mobjects\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2716\u001b[0m   \"\"\"\n\u001b[0;32m-> 2717\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGLOBAL_VARIABLES\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_collection\u001b[0;34m(key, scope)\u001b[0m\n\u001b[1;32m   5975\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mend_compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5976\u001b[0m   \"\"\"\n\u001b[0;32m-> 5977\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_collection\u001b[0;34m(self, name, scope)\u001b[0m\n\u001b[1;32m   3830\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3831\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mscope\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3832\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcollection\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3833\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3834\u001b[0m         \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def test_epoch():\n",
    "    epoch_size_list=tqdm([10,12,14])\n",
    "    score=[]\n",
    "    result=[]\n",
    "    for B in epoch_size_list:\n",
    "        model=create_model()\n",
    "        model.fit(X_train,y_train,epochs=B,verbose=1)\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        y_pred=[x[0] for x in y_pred]\n",
    "        s=roc_auc_score(y_test,y_pred)\n",
    "        score.append(s)\n",
    "        print(s)\n",
    "        if(s==max(score)):\n",
    "            result=[B,s]\n",
    "    epoch_size_list=list(epoch_size_list)\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(epoch_size_list,score,label='score')\n",
    "    ax.set_xlabel(r'epoch')\n",
    "    ax.set_ylabel(r'score')\n",
    "    plt.show()\n",
    "    return result\n",
    "result1=test_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1=[12,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "16000/16000 [==============================] - 52s 3ms/step - loss: 0.3261 - auc: 0.8858\n",
      "Epoch 2/12\n",
      "16000/16000 [==============================] - 39s 2ms/step - loss: 0.2039 - auc: 0.9415\n",
      "Epoch 3/12\n",
      "16000/16000 [==============================] - 39s 2ms/step - loss: 0.1282 - auc: 0.9601\n",
      "Epoch 4/12\n",
      "16000/16000 [==============================] - 39s 2ms/step - loss: 0.0788 - auc: 0.9719\n",
      "Epoch 5/12\n",
      "16000/16000 [==============================] - 39s 2ms/step - loss: 0.0522 - auc: 0.9796\n",
      "Epoch 6/12\n",
      "16000/16000 [==============================] - 39s 2ms/step - loss: 0.0403 - auc: 0.9845\n",
      "Epoch 7/12\n",
      "16000/16000 [==============================] - 38s 2ms/step - loss: 0.0319 - auc: 0.9878\n",
      "Epoch 8/12\n",
      "16000/16000 [==============================] - 38s 2ms/step - loss: 0.0253 - auc: 0.9901\n",
      "Epoch 9/12\n",
      "16000/16000 [==============================] - 38s 2ms/step - loss: 0.0257 - auc: 0.9918\n",
      "Epoch 10/12\n",
      "16000/16000 [==============================] - 38s 2ms/step - loss: 0.0233 - auc: 0.9930\n",
      "Epoch 11/12\n",
      "16000/16000 [==============================] - 38s 2ms/step - loss: 0.0242 - auc: 0.9939\n",
      "Epoch 12/12\n",
      "16000/16000 [==============================] - 38s 2ms/step - loss: 0.0244 - auc: 0.9946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [08:17<33:10, 497.56s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "Epoch 1/12\n",
      "16000/16000 [==============================] - 51s 3ms/step - loss: 0.3242 - auc: 0.8978\n",
      "Epoch 2/12\n",
      "16000/16000 [==============================] - 40s 2ms/step - loss: 0.2000 - auc: 0.9436\n",
      "Epoch 3/12\n",
      " 1140/16000 [=>............................] - ETA: 37s - loss: 0.1183 - auc: 0.9530"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-260-292e75f3735a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0mresult2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-260-292e75f3735a>\u001b[0m in \u001b[0;36mtest_batch\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mB\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbach_size_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDROPOUT\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2634\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'`inputs` should be a list or tuple.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2636\u001b[0;31m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2637\u001b[0m         \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2638\u001b[0m         \u001b[0marray_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    191\u001b[0m             \u001b[0mcandidate_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 193\u001b[0;31m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_keras_initialized'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    194\u001b[0m                     \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def test_batch():\n",
    "    bach_size_list=tqdm([10,15,20,25,30])\n",
    "    score=[]\n",
    "    result=[]\n",
    "    for B in bach_size_list:\n",
    "        model=create_model(L1=0,DROPOUT=0)\n",
    "        model.fit(X,y,epochs=result1[0],batch_size=12,verbose=1)\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        y_pred=[x[0] for x in y_pred]\n",
    "        s=roc_auc_score(y_test,y_pred)\n",
    "        score.append(s)\n",
    "        print(s)\n",
    "        if(s==max(score)):\n",
    "            result=[B,s]\n",
    "    bach_size_list=list(bach_size_list)\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(bach_size_list,score,label='score')\n",
    "    ax.set_xlabel(r'batch')\n",
    "    ax.set_ylabel(r'score')\n",
    "    plt.show()\n",
    "    return result\n",
    "result2=test_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 4242)"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "result2=[20,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/10 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "6400/6400 [==============================] - 83s 13ms/step - loss: 8.5546 - auc: 0.7438\n",
      "Epoch 2/20\n",
      "6400/6400 [==============================] - 73s 11ms/step - loss: 0.9619 - auc: 0.8566\n",
      "Epoch 3/20\n",
      "3324/6400 [==============>...............] - ETA: 34s - loss: 0.5179 - auc: 0.8832"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-0e517dccc713>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m \u001b[0mresult5\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_learn_rate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-190-0e517dccc713>\u001b[0m in \u001b[0;36mtest_learn_rate\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrate_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearn_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def test_learn_rate():\n",
    "    rate_list=tqdm(np.logspace(-4,0,10))\n",
    "    score=[]\n",
    "    result=[]\n",
    "    for r in rate_list:\n",
    "        model=create_model(learn_rate=r)\n",
    "        model.fit(X_train,y_train,epochs=20,batch_size=12,verbose=1)\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        y_pred=[x[0] for x in y_pred]\n",
    "        s=roc_auc_score(y_test,y_pred)\n",
    "        score.append(s)\n",
    "        print(s)\n",
    "        if(s==max(score)):\n",
    "            result=[r,s]\n",
    "    rate_list=list(rate_list)\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(rate_list,score,label='score')\n",
    "    ax.set_xlabel(r'batch')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel(r'score')\n",
    "    plt.show()\n",
    "    return result\n",
    "result5=test_learn_rate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_optimizer():\n",
    "    opt_list=['sgd','adam']\n",
    "    score=[]\n",
    "    result=[]\n",
    "    for o in opt_list:\n",
    "        model=create_model(optimizer=o)\n",
    "        model.fit(X_train,y_train,epochs=result1[0],batch_size=result2[0],verbose=1)\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        y_pred=[x[0] for x in y_pred]\n",
    "        s=roc_auc_score(y_test,y_pred)\n",
    "        score.append(s)\n",
    "        print(s)\n",
    "        if(s==max(score)):\n",
    "            result=[o,s]\n",
    "    return result\n",
    "result3=test_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "result3=['adam',0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-bb2eed91475a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mresult4\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-159-bb2eed91475a>\u001b[0m in \u001b[0;36mtest_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mloss_list\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hinge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'categorical_hinge'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mL\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresult2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-153-b2349b7577a0>\u001b[0m in \u001b[0;36mcreate_model\u001b[0;34m(size, optimizer, loss, L1, L2, DROPOUT)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkernel_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivity_regularizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mregularizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sigmoid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0moutput_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0moutput_weighted_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_weighted_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     metric_result = weighted_metric_fn(y_true, y_pred,\n\u001b[1;32m    419\u001b[0m                                                        \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                                                        mask=masks[i])\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;31m# Append to self.metrics_names, self.metric_tensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-153-b2349b7577a0>\u001b[0m in \u001b[0;36mauc\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mauc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mauc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mregularizers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    197\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 199\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def test_loss():\n",
    "    score=[]\n",
    "    result=[]\n",
    "    loss_list=['hinge','categorical_hinge','binary_crossentropy','categorical_crossentropy']\n",
    "    for L in loss_list:\n",
    "        model=create_model(optimizer=result3[0],loss=L)\n",
    "        model.fit(X_train,y_train,epochs=result1[0],batch_size=result2[0],verbose=1)\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        y_pred=[x[0] for x in y_pred]\n",
    "        s=roc_auc_score(y_test,y_pred)\n",
    "        score.append(s)\n",
    "        print(s)\n",
    "        if(s==max(score)):\n",
    "            result=[L,s]\n",
    "    return result\n",
    "result4=test_loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 89s 7ms/step - loss: 0.3463 - auc: 0.8854\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.2132 - auc: 0.9355\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.1348 - auc: 0.9559\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0866 - auc: 0.9690\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0581 - auc: 0.9773\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0456 - auc: 0.9828\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0357 - auc: 0.9863\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0334 - auc: 0.9889\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0312 - auc: 0.9907\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0283 - auc: 0.9920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 20%|██        | 1/5 [13:08<52:33, 788.42s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9465943615153579\n",
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 94s 7ms/step - loss: 0.3456 - auc: 0.8827\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.2112 - auc: 0.9354\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.1340 - auc: 0.9570\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0832 - auc: 0.9697\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0569 - auc: 0.9781\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0432 - auc: 0.9834\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0373 - auc: 0.9869\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0332 - auc: 0.9894\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0292 - auc: 0.9911\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0276 - auc: 0.9924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 40%|████      | 2/5 [26:30<39:37, 792.61s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9394065241014282\n",
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 90s 7ms/step - loss: 0.3465 - auc: 0.8889\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.2137 - auc: 0.9366\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.1362 - auc: 0.9568\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.0895 - auc: 0.9695\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.0587 - auc: 0.9777\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0456 - auc: 0.9832\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.0414 - auc: 0.9867\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.0350 - auc: 0.9891\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.0336 - auc: 0.9909\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.0329 - auc: 0.9922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 60%|██████    | 3/5 [39:57<26:33, 796.70s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9408907121156189\n",
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 91s 7ms/step - loss: 0.3517 - auc: 0.8832\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.2208 - auc: 0.9369\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.1388 - auc: 0.9568\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0892 - auc: 0.9701\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0615 - auc: 0.9784\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0516 - auc: 0.9837\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.0411 - auc: 0.9872\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0379 - auc: 0.9895\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.0344 - auc: 0.9913\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0328 - auc: 0.9925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 80%|████████  | 4/5 [53:21<13:18, 798.88s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9348855024012174\n",
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 94s 7ms/step - loss: 0.3625 - auc: 0.8873\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 80s 6ms/step - loss: 0.2283 - auc: 0.9374\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.1467 - auc: 0.9576\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0958 - auc: 0.9705\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0670 - auc: 0.9788\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0518 - auc: 0.9840\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 75s 6ms/step - loss: 0.0468 - auc: 0.9874\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 76s 6ms/step - loss: 0.0406 - auc: 0.9898\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 78s 6ms/step - loss: 0.0362 - auc: 0.9914\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 77s 6ms/step - loss: 0.0389 - auc: 0.9927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "100%|██████████| 5/5 [1:06:51<00:00, 802.45s/it]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9336218520309394\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def test_l1():\n",
    "    l1_list=tqdm(np.logspace(-6,-4,5))\n",
    "    score=[]\n",
    "    result=[]\n",
    "    for l1 in l1_list:\n",
    "        model=create_model(L1=l1,DROPOUT=0.022)\n",
    "        model.fit(X_train,y_train,epochs=10,batch_size=5,verbose=1)\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        y_pred=[x[0] for x in y_pred]\n",
    "        s=roc_auc_score(y_test,y_pred)\n",
    "        score.append(s)\n",
    "        print(s)\n",
    "        if(s==max(score)):\n",
    "            result=[l1,s]\n",
    "    l1_list=list(l1_list)\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(l1_list,score,label='score')\n",
    "    ax.set_xlabel(r'batch')\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_ylabel(r'score')\n",
    "    plt.show()\n",
    "    return result\n",
    "result5=test_l1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004641588833612777"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.logspace(-4,-1,10)[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_l2():\n",
    "    l2_list=tqdm(np.logspace(-2,-3,30))\n",
    "    score=[]\n",
    "    result=[]\n",
    "    for l2 in l2_list:\n",
    "        model=create_model(optimizer=result3[0],loss=result4[0],L1=result5[0],L2=l2)\n",
    "        model.fit(X_train,y_train,epochs=result1[0],verbose=1)\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        y_pred=[x[0] for x in y_pred]\n",
    "        s=roc_auc_score(y_test,y_pred)\n",
    "        score.append(s)\n",
    "        print(s)\n",
    "        if(s==max(score)):\n",
    "            result=[l2,s]\n",
    "    l2_list=list(l2_list)\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(l2_list,score,label='score')\n",
    "    ax.set_xscale('log')   \n",
    "    ax.set_xlabel(r'batch')\n",
    "    ax.set_ylabel(r'score')\n",
    "    plt.show()\n",
    "    return result\n",
    "result6=test_l2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.3380 - auc: 0.8753\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 12s 948us/step - loss: 0.1974 - auc: 0.9397\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 12s 951us/step - loss: 0.1218 - auc: 0.9599\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 12s 969us/step - loss: 0.0756 - auc: 0.9722\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 12s 966us/step - loss: 0.0521 - auc: 0.9800\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 12s 957us/step - loss: 0.0392 - auc: 0.9848\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 12s 952us/step - loss: 0.0326 - auc: 0.9882\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 12s 949us/step - loss: 0.0269 - auc: 0.9904\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 12s 950us/step - loss: 0.0234 - auc: 0.9921\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 12s 950us/step - loss: 0.0206 - auc: 0.9933\n",
      "0.9469344834219817\n",
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.3388 - auc: 0.8838\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 12s 960us/step - loss: 0.2022 - auc: 0.9386\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 12s 954us/step - loss: 0.1214 - auc: 0.9591\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 12s 949us/step - loss: 0.0760 - auc: 0.9718\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 12s 952us/step - loss: 0.0487 - auc: 0.9796\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 12s 948us/step - loss: 0.0380 - auc: 0.9847\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 12s 945us/step - loss: 0.0306 - auc: 0.9880\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 12s 947us/step - loss: 0.0263 - auc: 0.9904\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 12s 947us/step - loss: 0.0231 - auc: 0.9920\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 12s 944us/step - loss: 0.0240 - auc: 0.9932\n",
      "0.9458894209522027\n",
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.3411 - auc: 0.8718\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 12s 949us/step - loss: 0.1965 - auc: 0.9387\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 12s 951us/step - loss: 0.1208 - auc: 0.9597\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 12s 953us/step - loss: 0.0756 - auc: 0.9721\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 12s 947us/step - loss: 0.0465 - auc: 0.9799\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 12s 953us/step - loss: 0.0363 - auc: 0.9851\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 12s 947us/step - loss: 0.0252 - auc: 0.9884\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 12s 944us/step - loss: 0.0227 - auc: 0.9907\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 12s 946us/step - loss: 0.0235 - auc: 0.9924\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 12s 947us/step - loss: 0.0216 - auc: 0.9935\n",
      "0.9443289763067182\n",
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.3375 - auc: 0.8718\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 12s 942us/step - loss: 0.2003 - auc: 0.9391\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 12s 944us/step - loss: 0.1206 - auc: 0.9598\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 12s 940us/step - loss: 0.0762 - auc: 0.9721\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 12s 943us/step - loss: 0.0504 - auc: 0.9798\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 12s 943us/step - loss: 0.0351 - auc: 0.9849\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 12s 945us/step - loss: 0.0316 - auc: 0.9882\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 12s 941us/step - loss: 0.0241 - auc: 0.9905\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 12s 938us/step - loss: 0.0241 - auc: 0.9921\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 12s 941us/step - loss: 0.0262 - auc: 0.9933\n",
      "0.9469479149877209\n",
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.3441 - auc: 0.8731\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 12s 944us/step - loss: 0.1995 - auc: 0.9370\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 12s 942us/step - loss: 0.1226 - auc: 0.9588\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 12s 943us/step - loss: 0.0766 - auc: 0.9715\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 12s 934us/step - loss: 0.0567 - auc: 0.9793\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 12s 949us/step - loss: 0.0357 - auc: 0.9844\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 12s 974us/step - loss: 0.0307 - auc: 0.9878\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 12s 958us/step - loss: 0.0263 - auc: 0.9902\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 12s 968us/step - loss: 0.0219 - auc: 0.9919\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 12s 926us/step - loss: 0.0268 - auc: 0.9931\n",
      "0.9450828770933746\n",
      "Epoch 1/10\n",
      "12800/12800 [==============================] - 26s 2ms/step - loss: 0.3420 - auc: 0.8708\n",
      "Epoch 2/10\n",
      "12800/12800 [==============================] - 12s 943us/step - loss: 0.1978 - auc: 0.9382\n",
      "Epoch 3/10\n",
      "12800/12800 [==============================] - 12s 946us/step - loss: 0.1228 - auc: 0.9595\n",
      "Epoch 4/10\n",
      "12800/12800 [==============================] - 12s 944us/step - loss: 0.0708 - auc: 0.9720\n",
      "Epoch 5/10\n",
      "12800/12800 [==============================] - 12s 944us/step - loss: 0.0493 - auc: 0.9800\n",
      "Epoch 6/10\n",
      "12800/12800 [==============================] - 12s 946us/step - loss: 0.0367 - auc: 0.9850\n",
      "Epoch 7/10\n",
      "12800/12800 [==============================] - 12s 960us/step - loss: 0.0344 - auc: 0.9882\n",
      "Epoch 8/10\n",
      "12800/12800 [==============================] - 12s 944us/step - loss: 0.0307 - auc: 0.9904\n",
      "Epoch 9/10\n",
      "12800/12800 [==============================] - 12s 946us/step - loss: 0.0219 - auc: 0.9920\n",
      "Epoch 10/10\n",
      "12800/12800 [==============================] - 12s 942us/step - loss: 0.0226 - auc: 0.9933\n",
      "0.9438044953284147\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#X_train, X_test, y_train, y_test=train_test_split(X[:10000], y[:10000], test_size=.2, random_state=SEED)   \n",
    "def test_d():\n",
    "    D_list=[0.016,0.018,0.02,0.022,0.024,0.026]\n",
    "    score=[]\n",
    "    result=[]\n",
    "    for D in D_list:\n",
    "        model=create_model(DROPOUT=D,L1=0)\n",
    "        model.fit(X_train,y_train,epochs=10,verbose=1)\n",
    "        y_pred=model.predict_proba(X_test)\n",
    "        y_pred=[x[0] for x in y_pred]\n",
    "        s=roc_auc_score(y_test,y_pred)\n",
    "        score.append(s)\n",
    "        print(s)\n",
    "        if(s==max(score)):\n",
    "            result=[D,s]\n",
    "    D_list=list(D_list)\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(1,1,1)\n",
    "    ax.plot(D_list,score,label='score')\n",
    "    ax.set_xscale('log')   \n",
    "    ax.set_xlabel(r'batch')\n",
    "    ax.set_ylabel(r'score')\n",
    "    plt.show()\n",
    "    return result\n",
    "result7=test_d()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.022, 0.9469479149877209]"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=False, class_weight=None, criterion='gini',\n",
       "           max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function matplotlib.pyplot.show(*args, **kw)>"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.hist(clf.feature_importances_,bins=100,range=(0,0.0002))\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "clf1=SVC(C=0.03,random_state=SEED,kernel=\"linear\" ,probability=True)\n",
    "clf2=MLPClassifier((30, 2),solver='lbfgs',alpha=120,early_stopping=False, random_state=SEED)\n",
    "clf3=LogisticRegression(C=0.38486969)\n",
    "#clf4=create_model()\n",
    "clf4=AdaBoostClassifier(n_estimators=160)\n",
    "clf_list=[clf1,clf2,clf3]\n",
    "\n",
    "score=[]  \n",
    "clf1.fit(X_train,y_train)\n",
    "y_1=clf1.predict_proba(X_test)\n",
    "y_1=[x[1] for x in y_1]\n",
    "score.append(roc_auc_score(y_test,y_1))  \n",
    "\n",
    "clf2.fit(X_train,y_train)\n",
    "y_2=clf2.predict_proba(X_test)\n",
    "y_2=[x[1] for x in y_2]\n",
    "score.append(roc_auc_score(y_test,y_2))  \n",
    "\n",
    "clf3.fit(X_train,y_train)\n",
    "y_3=clf3.predict_proba(X_test)\n",
    "y_3=[x[1] for x in y_3]\n",
    "score.append(roc_auc_score(y_test,y_3))  \n",
    "\n",
    "\n",
    "clf4.fit(X_train,y_train)\n",
    "y_4=clf4.predict_proba(X_test)\n",
    "y_4=[x[1] for x in y_4]\n",
    "score.append(roc_auc_score(y_test,y_4))\n",
    "#clf5.fit(X_train,y_train)\n",
    "#y_5=clf5.predict_proba(X_test)\n",
    "#y_5=[x[1] for x in y_5]\n",
    "#score.append(roc_auc_score(y_test,y_5))\n",
    "\n",
    "y_list=[y_1,y_2,y_3,y_4]\n",
    "\n",
    "y_f=ave(y_list,[0.1,0.4,0.4,0.1])\n",
    "score.append(roc_auc_score(y_test,y_f))\n",
    "\n",
    "#y_5=ensemble([clf1,clf2,clf3],X_test,[0.3,0.3,0.4])\n",
    "#score.append(roc_auc_score(y_test,y_5))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9456578347622786,\n",
       " 0.9580740174593023,\n",
       " 0.9582078998403811,\n",
       " 0.9399825649611178,\n",
       " 0.9583266175504637]"
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584197719580102"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_f=ave([y_2,y_3],[0.5,0.5])\n",
    "roc_auc_score(y_test,y_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list=[y_1,y_2,y_3,y_4]\n",
    "\n",
    "y_f=ave(y_list,[0.1,0.4,0.4,0.1])\n",
    "score.append(roc_auc_score(y_test,y_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf3=LogisticRegression(C=0.38486969)\n",
    "clf3.fit(X,y)\n",
    "y_pred=clf3.predict_proba(X_handout)\n",
    "y_pred=[x[1] for x in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf4.fit(X_train,y_train)\n",
    "y_4=clf4.predict_proba(X_test)\n",
    "y_4=[x[0] for x in y_4]\n",
    "score.append(roc_auc_score(y_test,y_4))\n",
    "#clf5.fit(X_train,y_train)\n",
    "#y_5=clf5.predict_proba(X_test)\n",
    "#y_5=[x[1] for x in y_5]\n",
    "#score.append(roc_auc_score(y_test,y_5))\n",
    "y_list=[y_1,y_2,y_3,y_4]\n",
    "y_f=ave(y_list,[0.25,0.25,0.25,0.25])\n",
    "score.append(roc_auc_score(y_test,y_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9687884244224583,\n",
       " 0.9941414777548641,\n",
       " 0.009725372404573496,\n",
       " 0.9908698600614783,\n",
       " 0.8655210493412853,\n",
       " 0.981731130548874,\n",
       " 0.9856779380155124,\n",
       " 0.996231744959919,\n",
       " 0.906078256247885,\n",
       " 0.9483977184748908,\n",
       " 0.43068363181909264,\n",
       " 0.6337485530982624,\n",
       " 0.8159646436843163,\n",
       " 0.9606026298000772,\n",
       " 0.9659446663115073,\n",
       " 0.9822906064768094,\n",
       " 0.028544883177773372,\n",
       " 0.9931313000697394,\n",
       " 0.29728104173797976,\n",
       " 0.9984589203023468,\n",
       " 0.9861032503581164,\n",
       " 0.9834808689155092,\n",
       " 0.021123733798514954,\n",
       " 0.9029205770595556,\n",
       " 0.9241421843764448,\n",
       " 0.5096883370934068,\n",
       " 0.20656867025452263,\n",
       " 0.9973362105246525,\n",
       " 0.7426246915454571,\n",
       " 0.9832069005968974,\n",
       " 0.9792342913407224,\n",
       " 0.07793561893009093,\n",
       " 0.997035358038844,\n",
       " 0.5603163448904322,\n",
       " 0.9717779311238176,\n",
       " 0.2105755538764732,\n",
       " 0.9716594392659242,\n",
       " 0.9787753960944633,\n",
       " 0.9822084350774537,\n",
       " 0.046024067384655476,\n",
       " 0.48967429397936824,\n",
       " 0.9892313592807193,\n",
       " 0.9721890365812949,\n",
       " 0.9050212508212591,\n",
       " 0.9839477079066516,\n",
       " 0.9783113744186124,\n",
       " 0.27081484225636,\n",
       " 0.35211776873456835,\n",
       " 0.966133498799347,\n",
       " 0.860264163269073,\n",
       " 0.9636498212739024,\n",
       " 0.08259960894616014,\n",
       " 0.9178674169209249,\n",
       " 0.315702615025622,\n",
       " 0.9858526592734964,\n",
       " 0.9579656803532925,\n",
       " 0.9766453251859919,\n",
       " 0.9895119419098672,\n",
       " 0.18582668871725427,\n",
       " 0.983944213598404,\n",
       " 0.9775034962219877,\n",
       " 0.8822847302020801,\n",
       " 0.861255386438063,\n",
       " 0.19614288314290307,\n",
       " 0.2019398722047735,\n",
       " 0.9806977246726071,\n",
       " 0.9920477127890923,\n",
       " 0.20899151048234543,\n",
       " 0.2927056779638496,\n",
       " 0.7963852885408196,\n",
       " 0.9837520388720006,\n",
       " 0.9837987623251524,\n",
       " 0.03952839544018083,\n",
       " 0.9764907510535537,\n",
       " 0.9066427420418269,\n",
       " 0.9892313592807193,\n",
       " 0.9221525822038982,\n",
       " 0.42278532111925005,\n",
       " 0.9247427777268268,\n",
       " 0.9947223892707041,\n",
       " 0.818953678596648,\n",
       " 0.0856522713188731,\n",
       " 0.16956577156732733,\n",
       " 0.7004720868553604,\n",
       " 0.9678768602708514,\n",
       " 0.8267458869601901,\n",
       " 0.9782837744217174,\n",
       " 0.9880488580342293,\n",
       " 0.6682171616937396,\n",
       " 0.6168969658981294,\n",
       " 0.6320810979273244,\n",
       " 0.1356675433515333,\n",
       " 0.05266106006842686,\n",
       " 0.9911076690110978,\n",
       " 0.9715755856389949,\n",
       " 0.5111063526007456,\n",
       " 0.03275111157411026,\n",
       " 0.9826972399442491,\n",
       " 0.04848765268621957,\n",
       " 0.007690521757816926,\n",
       " 0.9655670775658712,\n",
       " 0.973478453905186,\n",
       " 0.9886978005132355,\n",
       " 0.26805156423329546,\n",
       " 0.8361581876619022,\n",
       " 0.011600434315941932,\n",
       " 0.9773384048832324,\n",
       " 0.9970745267252508,\n",
       " 0.1330020047977064,\n",
       " 0.9839221832675416,\n",
       " 0.9852692977495187,\n",
       " 0.9757424507250197,\n",
       " 0.9832797635408129,\n",
       " 0.025349836741698106,\n",
       " 0.056211486529120336,\n",
       " 0.7923835339381746,\n",
       " 0.6777027555047488,\n",
       " 0.9916111325768749,\n",
       " 0.46543223536967515,\n",
       " 0.9974075082165272,\n",
       " 0.9858526120421854,\n",
       " 0.9356547548558748,\n",
       " 0.9034865140364262,\n",
       " 0.344424992154192,\n",
       " 0.9559587007550522,\n",
       " 0.16946457517128488,\n",
       " 0.9886743785030958,\n",
       " 0.8938037201582123,\n",
       " 0.0792182456714341,\n",
       " 0.9045111270757522,\n",
       " 0.9960548075630755,\n",
       " 0.986847847515852,\n",
       " 0.9892313592807193,\n",
       " 0.9934036793180256,\n",
       " 0.6922812312045039,\n",
       " 0.9941013905688137,\n",
       " 0.9789998416213409,\n",
       " 0.9924623519461004,\n",
       " 0.9725104016050424,\n",
       " 0.969346207522239,\n",
       " 0.9640369982334264,\n",
       " 0.996231744959919,\n",
       " 0.20545829687848494,\n",
       " 0.9830991859474612,\n",
       " 0.9961925552357225,\n",
       " 0.9649055412715598,\n",
       " 0.41674174150500554,\n",
       " 0.9434777283770237,\n",
       " 0.975947527728374,\n",
       " 0.6160818376946929,\n",
       " 0.9775303099717543,\n",
       " 0.9826240338119536,\n",
       " 0.27194178355965826,\n",
       " 0.5151452946164867,\n",
       " 0.7761064307776911,\n",
       " 0.15557626676514735,\n",
       " 0.9820296199227512,\n",
       " 0.9674429068903596,\n",
       " 0.9919796906288311,\n",
       " 0.982926824279157,\n",
       " 0.996231744959919,\n",
       " 0.4964901388287293,\n",
       " 0.045894888742055606,\n",
       " 0.1375227687186935,\n",
       " 0.9360474390098686,\n",
       " 0.5748640907321488,\n",
       " 0.32220948887569545,\n",
       " 0.30850331470188586,\n",
       " 0.24216477366637001,\n",
       " 0.0041559092430515365,\n",
       " 0.9088524353169746,\n",
       " 0.9389253708816623,\n",
       " 0.986988625925978,\n",
       " 0.14168251699755596,\n",
       " 0.9787846754260661,\n",
       " 0.9956564334314986,\n",
       " 0.9947491146789549,\n",
       " 0.19981551327244207,\n",
       " 0.9886864453995255,\n",
       " 0.6648592966106479,\n",
       " 0.9868157632322833,\n",
       " 0.7652546955682679,\n",
       " 0.9720384732465012,\n",
       " 0.9876198672838056,\n",
       " 0.28947605856857483,\n",
       " 0.9933065000268789,\n",
       " 0.13789234030527486,\n",
       " 0.9977451863451001,\n",
       " 0.990742990272975,\n",
       " 0.4344548959605278,\n",
       " 0.9930039876607999,\n",
       " 0.07249562356119665,\n",
       " 0.9223239246435158,\n",
       " 0.2137497856924807,\n",
       " 0.7742742373269899,\n",
       " 0.9719505347154854,\n",
       " 0.9850428379768834,\n",
       " 0.9837987623251524,\n",
       " 0.9898271783173574,\n",
       " 0.996231744959919,\n",
       " 0.05395250455694456,\n",
       " 0.10554347004865727,\n",
       " 0.1041044294524428,\n",
       " 0.9738328838538189,\n",
       " 0.948624999108646,\n",
       " 0.436514688793457,\n",
       " 0.9817109205897901,\n",
       " 0.9919936552636461,\n",
       " 0.1407600959880283,\n",
       " 0.9387417971356722,\n",
       " 0.9586168379326014,\n",
       " 0.9707435142175527,\n",
       " 0.9287541784032813,\n",
       " 0.4677298179571221,\n",
       " 0.6909008194213335,\n",
       " 0.9134869437852176,\n",
       " 0.8354661721024297,\n",
       " 0.0535294776025973,\n",
       " 0.9827067979503791,\n",
       " 0.1127162443455435,\n",
       " 0.8333433313935853,\n",
       " 0.48758779193725943,\n",
       " 0.9699397003095929,\n",
       " 0.11963656754514085,\n",
       " 0.913805565707476,\n",
       " 0.044386467208899716,\n",
       " 0.9837987623251524,\n",
       " 0.028663038691800424,\n",
       " 0.9890017226067752,\n",
       " 0.0856522713188731,\n",
       " 0.9908698600614783,\n",
       " 0.989557472016603,\n",
       " 0.07422807128337183,\n",
       " 0.046024067384655476,\n",
       " 0.6848328994562412,\n",
       " 0.9789624237884332,\n",
       " 0.9644959431084161,\n",
       " 0.2688112668272894,\n",
       " 0.8016642501438095,\n",
       " 0.9123783737071036,\n",
       " 0.9604186769242185,\n",
       " 0.007690521757816926,\n",
       " 0.13465289048938078,\n",
       " 0.9308340100399334,\n",
       " 0.0005640305202765372,\n",
       " 0.8285819755777595,\n",
       " 0.9839022137944168,\n",
       " 0.9687930424439266,\n",
       " 0.8150360630694228,\n",
       " 0.9666270943258234,\n",
       " 0.9685554752314254,\n",
       " 0.9887347657678915,\n",
       " 0.9837987623251524,\n",
       " 0.3856108474232728,\n",
       " 0.9890026310251468,\n",
       " 0.2032966934007654,\n",
       " 0.9757424507250197,\n",
       " 0.9667529537562559,\n",
       " 0.14508490689120634,\n",
       " 0.1497311283329894,\n",
       " 0.08494736436728245,\n",
       " 0.1924303346291848,\n",
       " 0.9308787454958792,\n",
       " 0.9159276799724331,\n",
       " 0.9756290425013912,\n",
       " 0.3823053110968131,\n",
       " 0.9966596652158591,\n",
       " 0.9876184568450567,\n",
       " 0.11099673800209642,\n",
       " 0.00012365998095043018,\n",
       " 0.9849573293042685,\n",
       " 0.94468502288814,\n",
       " 0.932538477515365,\n",
       " 0.9862577493985649,\n",
       " 0.23099988954978756,\n",
       " 0.8371026512648084,\n",
       " 0.6933852955680793,\n",
       " 0.45908253861460024,\n",
       " 0.06110020470446087,\n",
       " 0.44742011315696983,\n",
       " 0.9725163501461918,\n",
       " 0.7139854787304751,\n",
       " 0.16605669297753856,\n",
       " 0.9106695874296505,\n",
       " 0.9864776025296474,\n",
       " 0.890700046554828,\n",
       " 0.9952214501696117,\n",
       " 0.246590973059561,\n",
       " 0.9837411346891699,\n",
       " 0.9465381720192345,\n",
       " 0.15220185924315,\n",
       " 0.7726994249715375,\n",
       " 0.1580514598965791,\n",
       " 0.6656516604717428,\n",
       " 0.6806348444782321,\n",
       " 0.9607321642249331,\n",
       " 0.06826399034909814,\n",
       " 0.9266217222894423,\n",
       " 0.9796884434059694,\n",
       " 0.9837987623251524,\n",
       " 0.9514176939986821,\n",
       " 0.9934036793180256,\n",
       " 0.9784742090530647,\n",
       " 0.9869980598812296,\n",
       " 0.29295885085231343,\n",
       " 0.22006724246413212,\n",
       " 0.2021772911440709,\n",
       " 0.8304183514501744,\n",
       " 0.06504626877250985,\n",
       " 0.9387133062125319,\n",
       " 0.9171238571439728,\n",
       " 0.3517123146907877,\n",
       " 0.007690521757816926,\n",
       " 0.31946137439465505,\n",
       " 0.9853888304185897,\n",
       " 0.22929211185309772,\n",
       " 0.9699419247542915,\n",
       " 0.9636122450964191,\n",
       " 0.14094707984579946,\n",
       " 0.20008969105546093,\n",
       " 0.8665220474585734,\n",
       " 0.9899091871251084,\n",
       " 0.9825912215376642,\n",
       " 0.9590089351031325,\n",
       " 0.9131724607906958,\n",
       " 0.2590296785520366,\n",
       " 0.935272907092595,\n",
       " 0.9864537033004143,\n",
       " 0.8430069179675752,\n",
       " 0.16416250667815346,\n",
       " 0.952057907476223,\n",
       " 0.10827833909991569,\n",
       " 0.9972456325861153,\n",
       " 0.3932901409855105,\n",
       " 0.9838219430089489,\n",
       " 0.8323347433119241,\n",
       " 0.11184223389219206,\n",
       " 0.344424992154192,\n",
       " 0.9411874891131005,\n",
       " 0.9930062041020732,\n",
       " 0.9880488580342293,\n",
       " 0.9837987623251524,\n",
       " 0.9838695449246286,\n",
       " 0.3334048554128247,\n",
       " 0.15108421271079187,\n",
       " 0.03346973918897789,\n",
       " 0.055855236678890585,\n",
       " 0.9677273275674603,\n",
       " 0.9766453251859919,\n",
       " 0.1432568808504171,\n",
       " 0.9307318068306606,\n",
       " 0.9866098360749176,\n",
       " 0.9953599000740142,\n",
       " 0.995721693605358,\n",
       " 0.9908766043702063,\n",
       " 0.9972463047767711,\n",
       " 0.885521154436945,\n",
       " 0.975924951259492,\n",
       " 0.9033337854745316,\n",
       " 0.6232588601066664,\n",
       " 0.8991681393659415,\n",
       " 0.9787768417898761,\n",
       " 0.9772863495948652,\n",
       " 0.9917738833707008,\n",
       " 0.9884582271525446,\n",
       " 0.9727662067657449,\n",
       " 0.07513591275512099,\n",
       " 0.98472656952229,\n",
       " 0.22161327833769162,\n",
       " 0.9837987623251524,\n",
       " 0.9467624920476355,\n",
       " 0.996231744959919,\n",
       " 0.3028008813984505,\n",
       " 0.0555141761448229,\n",
       " 0.9725373593582942,\n",
       " 0.9951043531420679,\n",
       " 0.9917738833707008,\n",
       " 0.9392890458760285,\n",
       " 0.976479633156531,\n",
       " 0.7985919104735798,\n",
       " 0.3124381675442738,\n",
       " 0.8430555850409341,\n",
       " 0.9892313592807193,\n",
       " 0.9632289393048552,\n",
       " 0.2738720054346562,\n",
       " 0.9946428736363646,\n",
       " 0.3475090585983338,\n",
       " 0.9802658549922849,\n",
       " 0.8301103959392926,\n",
       " 0.9917120328456663,\n",
       " 0.9567809292209288,\n",
       " 0.6656516604717428,\n",
       " 0.876747649974872,\n",
       " 0.9832056487095687,\n",
       " 0.9787759606560847,\n",
       " 0.9936516982805188,\n",
       " 0.9826359358392748,\n",
       " 0.9860030888620063,\n",
       " 0.9935730363169587,\n",
       " 0.9875894693380081,\n",
       " 0.11724882927764135,\n",
       " 0.9823425997750891,\n",
       " 0.6218862155838194,\n",
       " 0.042844337736874016,\n",
       " 0.9437505947439206,\n",
       " 0.5515041608866804,\n",
       " 0.992897791415877,\n",
       " 0.11787211167950462,\n",
       " 0.9394492458777072,\n",
       " 0.9848285517890135,\n",
       " 0.5713238836255952,\n",
       " 0.9329219843672872,\n",
       " 0.9542945104757627,\n",
       " 0.9931842987123966,\n",
       " 0.9733948190061421,\n",
       " 0.9749561118714324,\n",
       " 0.20119084159690326,\n",
       " 0.5886407994305395,\n",
       " 0.963974009799895,\n",
       " 0.9803229467539638,\n",
       " 0.7117254148205772,\n",
       " 0.09100746172506213,\n",
       " 0.3492229753075583,\n",
       " 0.6051884310696861,\n",
       " 0.15069143350098047,\n",
       " 0.9969248421838222,\n",
       " 0.06288843029223079,\n",
       " 0.9701672131960255,\n",
       " 0.9890378543174989,\n",
       " 0.2626752727390448,\n",
       " 0.983354006742092,\n",
       " 0.08798087984572867,\n",
       " 0.9189908589849182,\n",
       " 0.9952854168879784,\n",
       " 0.8592412198179871,\n",
       " 0.9964444286720352,\n",
       " 0.9324625377098533,\n",
       " 0.9616279060072128,\n",
       " 0.006283630917196192,\n",
       " 0.3683222082864178,\n",
       " 0.4112993646031474,\n",
       " 0.996231744959919,\n",
       " 0.9230326227502275,\n",
       " 0.043963872052523834,\n",
       " 0.9633827731944953,\n",
       " 0.9219241592334816,\n",
       " 0.2677351612298656,\n",
       " 0.9911076690110978,\n",
       " 0.49705772134772863,\n",
       " 0.9899176119219217,\n",
       " 0.9917738833707008,\n",
       " 0.026718125448512042,\n",
       " 0.9717094127833604,\n",
       " 0.9632320987516276,\n",
       " 0.9698223720956759,\n",
       " 0.2248185303963548,\n",
       " 0.3385610918376989,\n",
       " 0.6463318924228616,\n",
       " 0.9897004129859429,\n",
       " 0.8946112052966034,\n",
       " 0.9315994975439689,\n",
       " 0.9902061786421713,\n",
       " 0.5413441039690989,\n",
       " 0.9783477857991837,\n",
       " 0.008261846060940492,\n",
       " 0.9848409843290432,\n",
       " 0.7753115086038753,\n",
       " 0.9837987623251524,\n",
       " 0.8948774049540766,\n",
       " 0.9656196084917787,\n",
       " 0.9883815193447726,\n",
       " 0.8134708111711271,\n",
       " 0.9923930589721823,\n",
       " 0.7968485750685428,\n",
       " 0.2657287348811448,\n",
       " 0.9924623519461004,\n",
       " 0.9481828177969851,\n",
       " 0.998206171786431,\n",
       " 0.8210647543749329,\n",
       " 0.12134474167681453,\n",
       " 0.9724067398836356,\n",
       " 0.9635034836491196,\n",
       " 0.9902105999658439,\n",
       " 0.9908698600614783,\n",
       " 0.17914320847123233,\n",
       " 0.08981305705992548,\n",
       " 0.00337197905166009,\n",
       " 0.9124701412887714,\n",
       " 0.9676053250815452,\n",
       " 0.12874956070168453,\n",
       " 0.9837930581394604,\n",
       " 0.14164754564434512,\n",
       " 0.9953518177784983,\n",
       " 0.9473826902386296,\n",
       " 0.9849402002751193,\n",
       " 0.2173533104484806,\n",
       " 0.9683044149599052,\n",
       " 0.8948119955750058,\n",
       " 0.5456701091392244,\n",
       " 0.9625865669066462,\n",
       " 0.09570623663130706,\n",
       " 0.23870448443377368,\n",
       " 0.962014962562147,\n",
       " 0.9704149668553712,\n",
       " 0.27185649060192474,\n",
       " 0.988019486974222,\n",
       " 0.02084551005319113,\n",
       " 0.9986877353032877,\n",
       " 0.9937316441050652,\n",
       " 0.8019401246023924,\n",
       " 0.9901957805292725,\n",
       " 0.7588131746356774,\n",
       " 0.9490701168587797,\n",
       " 0.21947994643548407,\n",
       " 0.9581693653698758,\n",
       " 0.789132332899483,\n",
       " 0.981387880797224,\n",
       " 0.9451559917054305,\n",
       " 0.9892737551733899,\n",
       " 0.9751612486193288,\n",
       " 0.10264070391295066,\n",
       " 0.10957059793751545,\n",
       " 0.3124381675442738,\n",
       " 0.026631506224272794,\n",
       " 0.9859013326610235,\n",
       " 0.9884681826645123,\n",
       " 0.9942064669221249,\n",
       " 0.9888474420448364,\n",
       " 0.23774624233617947,\n",
       " 0.9889759336452102,\n",
       " 0.8685686259824552,\n",
       " 0.977604498183468,\n",
       " 0.9981841953477028,\n",
       " 0.9892313592807193,\n",
       " 0.9929026904999317,\n",
       " 0.03440804619791282,\n",
       " 0.8269694967411279,\n",
       " 0.5518269732458447,\n",
       " 0.3869328820356719,\n",
       " 0.09822401844557649,\n",
       " 0.8434083876508787,\n",
       " 0.10454464953616927,\n",
       " 0.989158782938107,\n",
       " 0.9823164312539966,\n",
       " 0.1144388497772284,\n",
       " 0.993815347036593,\n",
       " 0.705047693704815,\n",
       " 0.9988594071589788,\n",
       " 0.1680273222471662,\n",
       " 0.974319595786439,\n",
       " 0.6311079758492739,\n",
       " 0.006610932115906798,\n",
       " 0.03465461543026671,\n",
       " 0.20911956192564485,\n",
       " 0.91410004910265,\n",
       " 0.7773008676443843,\n",
       " 0.1423537721203112,\n",
       " 0.9669657152224561,\n",
       " 0.9854594199908828,\n",
       " 0.6363860907721933,\n",
       " 0.9760573259940272,\n",
       " 0.8641399749172348,\n",
       " 0.019136224724334183,\n",
       " 0.9507444025747417,\n",
       " 0.8074093173834238,\n",
       " 0.018392731973464804,\n",
       " 0.9903625532058171,\n",
       " 0.06496233743795798,\n",
       " 0.050745051371776206,\n",
       " 0.9966090005035964,\n",
       " 0.8985542731666484,\n",
       " 0.9951141195957791,\n",
       " 0.973905658213172,\n",
       " 0.9852823276022101,\n",
       " 0.9362188317029233,\n",
       " 0.1127079194402012,\n",
       " 0.9912232890060203,\n",
       " 0.8177543649639101,\n",
       " 0.039858107700570855,\n",
       " 0.8826742531559565,\n",
       " 0.3116250757233533,\n",
       " 0.9952214501696117,\n",
       " 0.0015842483904929816,\n",
       " 0.1846455993269075,\n",
       " 0.12371101762000902,\n",
       " 0.1817411261242089,\n",
       " 0.979933220528991,\n",
       " 0.9403508488469707,\n",
       " 0.7085310487450094,\n",
       " 0.012001092969854188,\n",
       " 0.9933073645000077,\n",
       " 0.9882367029262199,\n",
       " 0.9376523560547968,\n",
       " 0.953687114813351,\n",
       " 0.6712218125044348,\n",
       " 0.27455784258154703,\n",
       " 0.8854752806984282,\n",
       " 0.08147045437972744,\n",
       " 0.044480757893668676,\n",
       " 0.9752909593913681,\n",
       " 0.919878399698147,\n",
       " 0.3193167545679608,\n",
       " 0.9953833499566191,\n",
       " 0.9400980421146512,\n",
       " 0.9092941381931238,\n",
       " 0.9901018423182758,\n",
       " 0.9581903215721738,\n",
       " 0.21128819025820145,\n",
       " 0.6656516604717428,\n",
       " 0.8892189222312576,\n",
       " 0.43222034018435085,\n",
       " 0.11168100645809376,\n",
       " 0.19651786561488327,\n",
       " 0.6656516604717428,\n",
       " 0.9861996476818251,\n",
       " 0.22759113237018336,\n",
       " 0.5850348720080095,\n",
       " 0.3558084031927621,\n",
       " 0.9892313592807193,\n",
       " 0.5314478201359099,\n",
       " 0.19588466186148856,\n",
       " 0.07991326401495336,\n",
       " 0.15016735741073395,\n",
       " 0.9399130295833401,\n",
       " 0.21703895775740734,\n",
       " 0.9494322465583019,\n",
       " 0.9586248382574756,\n",
       " 0.04468369723103971,\n",
       " 0.12456612626420616,\n",
       " 0.9568044467301671,\n",
       " 0.3555662647290486,\n",
       " 0.9850667089357331,\n",
       " 0.9850295001668958,\n",
       " 0.05353875341178216,\n",
       " 0.5527914692125624,\n",
       " 0.8763160546227035,\n",
       " 0.6656516604717428,\n",
       " 0.7492360056031242,\n",
       " 0.9234374140897594,\n",
       " 0.07435629105839647,\n",
       " 0.6932955053078279,\n",
       " 0.9039558950678752,\n",
       " 0.9873073495267408,\n",
       " 0.9878333474529433,\n",
       " 0.050745051371776206,\n",
       " 0.9719695533351285,\n",
       " 0.9957508849677182,\n",
       " 0.2771103677614791,\n",
       " 0.17816686852247576,\n",
       " 0.9547920209889001,\n",
       " 0.1708816794924104,\n",
       " 0.9805014648811665,\n",
       " 0.9620656679919625,\n",
       " 0.10728247160492443,\n",
       " 0.9421401526619207,\n",
       " 0.22878970981533364,\n",
       " 0.917471499825252,\n",
       " 0.12653726501578855,\n",
       " 0.10953425203782186,\n",
       " 0.9697664970690797,\n",
       " 0.9804091174085532,\n",
       " 0.9968157799900402,\n",
       " 0.979933220528991,\n",
       " 0.9722841413031742,\n",
       " 0.07961400328777346,\n",
       " 0.9900577566091202,\n",
       " 0.07070311731496903,\n",
       " 0.9160494574203968,\n",
       " 0.9917053699448364,\n",
       " 0.9631314410107831,\n",
       " 0.8665245082718693,\n",
       " 0.9520257774356312,\n",
       " 0.9774863743657463,\n",
       " 0.11441799869941427,\n",
       " 0.14031979282233276,\n",
       " 0.9659804232977942,\n",
       " 0.9803523356984281,\n",
       " 0.1757965856588939,\n",
       " 0.9701672131960255,\n",
       " 0.3594093729962915,\n",
       " 0.9874268819606502,\n",
       " 0.9472949522732123,\n",
       " 0.6345897440084254,\n",
       " 0.9150408850376497,\n",
       " 0.977535867967609,\n",
       " 0.9701907146849793,\n",
       " 0.8000707293571763,\n",
       " 0.9862597395999865,\n",
       " 0.14286252975207392,\n",
       " 0.9796089060638042,\n",
       " 0.9996318870700465,\n",
       " 0.5029422866987541,\n",
       " 0.056333166449725414,\n",
       " 0.9789164236656962,\n",
       " 0.2639027405440234,\n",
       " 0.0536432202048025,\n",
       " 0.9810569634364955,\n",
       " 0.950332084570693,\n",
       " 0.9830352100487816,\n",
       " 0.9837987623251524,\n",
       " 0.23281112373273494,\n",
       " 0.0035185959854979743,\n",
       " 0.542351581179427,\n",
       " 0.9837987623251524,\n",
       " 0.9970794529164455,\n",
       " 0.11082893582170783,\n",
       " 0.9954020035047927,\n",
       " 0.25605348079804313,\n",
       " 0.9668327706283223,\n",
       " 0.26868031450648333,\n",
       " 0.9308661903223987,\n",
       " 0.942887073947249,\n",
       " 0.2542976921840403,\n",
       " 0.985346022970316,\n",
       " 0.9723603171555034,\n",
       " 0.9901370050104433,\n",
       " 0.577684449737272,\n",
       " 0.8073821456065555,\n",
       " 0.8420919051008322,\n",
       " 0.9892313592807193,\n",
       " 0.996231744959919,\n",
       " 0.1735425181603838,\n",
       " 0.9983783211360276,\n",
       " 0.11745671146208159,\n",
       " 0.9918655101513628,\n",
       " 0.9018616200461465,\n",
       " 0.2317890231619043,\n",
       " 0.04912202030920054,\n",
       " 0.9915806318905394,\n",
       " 0.9887897251358251,\n",
       " 0.07435629105839647,\n",
       " 0.04385623039002451,\n",
       " 0.6656516604717428,\n",
       " 0.03425724230100269,\n",
       " 0.9923471578253983,\n",
       " 0.19539755984452434,\n",
       " 0.11043023418295372,\n",
       " 0.08527268472017979,\n",
       " 0.7109829795389542,\n",
       " 0.7322898000865737,\n",
       " 0.9884540806786033,\n",
       " 0.8444552727507796,\n",
       " 0.8542269243104942,\n",
       " 0.4746168468149219,\n",
       " 0.20530251214582618,\n",
       " 0.9942981123628042,\n",
       " 0.9872161012452476,\n",
       " 0.294655226700144,\n",
       " 0.9485216386862528,\n",
       " 0.9908958390238805,\n",
       " 0.00042738447918411193,\n",
       " 0.5737909144604965,\n",
       " 0.4735865132903546,\n",
       " 0.1371633415578345,\n",
       " 0.9735807788532819,\n",
       " 0.526022667814647,\n",
       " 0.9736416717950869,\n",
       " 0.9611917891641863,\n",
       " 0.008271227481065013,\n",
       " 0.5516797124781379,\n",
       " 0.996231744959919,\n",
       " 0.05161669405381197,\n",
       " 0.9485224367945783,\n",
       " 0.6888408150943232,\n",
       " 0.9908860789084092,\n",
       " 0.8062446091068818,\n",
       " 0.7915846993743807,\n",
       " 0.3337490270356761,\n",
       " 0.21223949357812,\n",
       " 0.8065503334774198,\n",
       " 0.00200197355864673,\n",
       " 0.481532610247302,\n",
       " 0.9983825366482921,\n",
       " 0.9119051747068891,\n",
       " 0.9668632647950677,\n",
       " 0.05569755630307838,\n",
       " 0.9247087075108817,\n",
       " 0.9611112900574644,\n",
       " 0.47164695362206444,\n",
       " 0.10308659210780513,\n",
       " 0.026953199884838352,\n",
       " 0.9752862098978025,\n",
       " 0.9941058922645146,\n",
       " 0.9600291094134444,\n",
       " 0.3979044346661825,\n",
       " 0.9917738833707008,\n",
       " 0.9596473025393911,\n",
       " 0.0279390065350964,\n",
       " 0.9760091757784305,\n",
       " 0.9069457285304839,\n",
       " 0.7933080200671796,\n",
       " 0.7379314767216945,\n",
       " 0.9883634331669238,\n",
       " 0.9722268892842336,\n",
       " 0.9812072539641806,\n",
       " 0.8810080621285945,\n",
       " 0.9758504019412758,\n",
       " 0.09208421902260022,\n",
       " 0.9842698939420348,\n",
       " 0.9580499353900577,\n",
       " 0.12086175748416106,\n",
       " 0.972806067734329,\n",
       " 0.9614096760280156,\n",
       " 0.9511494042983999,\n",
       " 0.9503032445138607,\n",
       " 0.9827929794052511,\n",
       " 0.08484764620855567,\n",
       " 0.344424992154192,\n",
       " 0.988714100796387,\n",
       " 0.17630250954985538,\n",
       " 0.8806480503191358,\n",
       " 0.12218902503482598,\n",
       " 0.1403001053503894,\n",
       " 0.06275220723949781,\n",
       " 0.9915170846909803,\n",
       " 0.7342025366218043,\n",
       " 0.9470156336673544,\n",
       " 0.8646059045014085,\n",
       " 0.991555869373412,\n",
       " 0.8510488851093804,\n",
       " 0.7532028096470835,\n",
       " 0.9875318104226275,\n",
       " 0.004257424984625113,\n",
       " 0.8565958817260665,\n",
       " 0.21470215931159098,\n",
       " 0.9729750295340354,\n",
       " 0.9929170189579134,\n",
       " 0.9934036793180256,\n",
       " 0.09941392753860767,\n",
       " 0.9499906967903385,\n",
       " 0.29111085197649467,\n",
       " 0.8630762544898369,\n",
       " 0.979933220528991,\n",
       " 0.4693265722091071,\n",
       " 0.15235705258685406,\n",
       " 0.9816814442330289,\n",
       " 0.2169010687567633,\n",
       " 0.9956596218540333,\n",
       " 0.976785541677321,\n",
       " 0.6724410344595361,\n",
       " 0.8911603730000561,\n",
       " 0.9260041681140749,\n",
       " 0.5291229707604372,\n",
       " 0.28773296308445395,\n",
       " 0.9636102198688732,\n",
       " 0.5744494899166916,\n",
       " 0.8869662220229699,\n",
       " 0.984748998983493,\n",
       " 0.9919312441593473,\n",
       " 0.992717188970732,\n",
       " 0.5677143435599858,\n",
       " 0.08202513667737477,\n",
       " 0.9907839744768759,\n",
       " 0.1681908286602053,\n",
       " 0.979694778631571,\n",
       " 0.44454589284438595,\n",
       " 0.9915396871430843,\n",
       " 0.04862578977816301,\n",
       " 0.10066326867380171,\n",
       " 0.9175904478308725,\n",
       " 0.9837987623251524,\n",
       " 0.15810794481642654,\n",
       " 0.07115570829967288,\n",
       " 0.6713088384161388,\n",
       " 0.6912083396295075,\n",
       " 0.9447237387598219,\n",
       " 0.9472006628045673,\n",
       " 0.6656516604717428,\n",
       " 0.7921653105416033,\n",
       " 0.27605700299890945,\n",
       " 0.14310301443633566,\n",
       " 0.057868194581848775,\n",
       " 0.053202789027744335,\n",
       " 0.8723315670700958,\n",
       " 0.9074842906749011,\n",
       " 0.028476047720351727,\n",
       " 0.1055984690408468,\n",
       " 0.8911991667683204,\n",
       " 0.9837987623251524,\n",
       " 0.836409682831412,\n",
       " 0.982932234824595,\n",
       " 0.9957931547959925,\n",
       " 0.09686929488856866,\n",
       " 0.9085682203656114,\n",
       " 0.9983534644862921,\n",
       " 0.9953198613790175,\n",
       " 0.2843829745628004,\n",
       " 0.9788850551419993,\n",
       " 0.9760249931309392,\n",
       " 0.9911076690110978,\n",
       " 0.32651684904837086,\n",
       " 0.989158782938107,\n",
       " 0.9938358263034097,\n",
       " 0.12347196895039259,\n",
       " 0.785516981546307,\n",
       " 0.019972593013196094,\n",
       " 0.15755215875142925,\n",
       " 0.922947811431363,\n",
       " 0.3960245037666372,\n",
       " 0.603822004089636,\n",
       " 0.9836628066996387,\n",
       " 0.03338777504666368,\n",
       " 0.996660464457746,\n",
       " 0.9837987623251524,\n",
       " 0.986859153401881,\n",
       " 0.2266411009176328,\n",
       " 0.06188509008144061,\n",
       " 0.8706798849775549,\n",
       " 0.9701860864497662,\n",
       " 0.6331183950453783,\n",
       " 0.9839440066276993,\n",
       " 0.9963824166074895,\n",
       " 0.43711656021256184,\n",
       " 0.9209476501766332,\n",
       " 0.9924140832102004,\n",
       " 0.3901940436554452,\n",
       " 0.7338149124036282,\n",
       " 0.03103582512420877,\n",
       " 0.8868755801459653,\n",
       " 0.6015968835514496,\n",
       " 0.8333433313935853,\n",
       " 0.4087450916853569,\n",
       " 0.023832349000871833,\n",
       " 0.9572835957403647,\n",
       " 0.17667365296175042,\n",
       " 0.9758729621341036,\n",
       " 0.9930884878456954,\n",
       " 0.055835048664295894,\n",
       " 0.9967523479726279,\n",
       " 0.9824390326347353,\n",
       " 0.742568210851185,\n",
       " 0.2678128702251117,\n",
       " 0.9955491144688184,\n",
       " 0.10793574491829638,\n",
       " 0.8812987909796404,\n",
       " 0.9238782322083449,\n",
       " 0.9970391629969245,\n",
       " 0.988430651766923,\n",
       " 0.9908698600614783,\n",
       " 0.9025992417884351,\n",
       " 0.41970368319622353,\n",
       " 0.9660025689952252,\n",
       " 0.3644807441787411,\n",
       " 0.8902652845711061,\n",
       " 0.9774239584370916,\n",
       " 0.981387880797224,\n",
       " 0.9756600680668007,\n",
       " 0.9159276799724331,\n",
       " 0.989158782938107,\n",
       " 0.9784011340291209,\n",
       " 0.0019243216882035563,\n",
       " 0.9644324580380057,\n",
       " 0.9880826634018438,\n",
       " 0.808488591128172,\n",
       " 0.77730787974114,\n",
       " 0.9945069171633835,\n",
       " 0.9947149783739819,\n",
       " 0.022138325840562745,\n",
       " 0.7935046325292836,\n",
       " 0.8163039663840486,\n",
       " 0.9041919671346919,\n",
       " 0.9941634269566019,\n",
       " 0.4205246034817002,\n",
       " 0.9304043468522282,\n",
       " 0.27215342844678836,\n",
       " 0.9938340508169015,\n",
       " 0.9816267138442889,\n",
       " 0.9874565514124368,\n",
       " 0.33100286144683877,\n",
       " 0.5246535738222651,\n",
       " 0.1494206257839059,\n",
       " 0.9778668342138922,\n",
       " 0.9757424507250197,\n",
       " 0.8379262984019836,\n",
       " 0.6023130537210686,\n",
       " 0.9596055660573035,\n",
       " 0.010671544536948518,\n",
       " 0.979933220528991,\n",
       " 0.986185070988869,\n",
       " 0.9989866743393996,\n",
       " 0.9664776560138639,\n",
       " 0.31476485142643484,\n",
       " 0.9838897453825143,\n",
       " 0.9611500274916734,\n",
       " 0.06494338834923641,\n",
       " 0.9889535779863347,\n",
       " 0.9837987623251524,\n",
       " 0.972378612305128,\n",
       " 0.1856459104533682,\n",
       " 0.9898962605924159,\n",
       " 0.9500711321686174,\n",
       " 0.7176765980731187,\n",
       " 0.9302676033512863,\n",
       " 0.9851545103652484,\n",
       " 0.28918927912458603,\n",
       " 0.9308340100399334,\n",
       " 0.9770741276141529,\n",
       " 0.6724853961943773,\n",
       " 0.9936863751297614,\n",
       " 0.2604625887072144,\n",
       " ...]"
      ]
     },
     "execution_count": 359,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9456578347622786,\n",
       " 0.9512958428004208,\n",
       " 0.04178213480439308,\n",
       " 0.06001743503888221,\n",
       " 0.9156870289203274]"
      ]
     },
     "execution_count": 358,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_list=[y_1,y_2,y_3,y_4]\n",
    "y_5=ave(y_list,[0.25,0.25,0.25,0.25])\n",
    "score.append(roc_auc_score(y_test,y_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_4=clf4.predict_proba(X_test)\n",
    "y_4=[x[0] for x in y_4]\n",
    "score.append(roc_auc_score(y_test,y_4))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_5=clf5.predict_proba(X_test)\n",
    "y_5=[x[1] for x in y_5]\n",
    "score.append(roc_auc_score(y_test,y_5))\n",
    "\n",
    "\n",
    "\n",
    "y_list=[y_1,y_2,y_3,y_4,y_5]\n",
    "y_f=ave(y_list,[0.2,0.2,0.2,0.2,0.2])\n",
    "score.append(roc_auc_score(y_test,y_f))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_4=ensemble([clf1,clf2,clf3],X_test,[0.3,0.3,0.4])\n",
    "score.append(roc_auc_score(y_test,y_4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_3=clf3.predict_proba(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9380991409903603,\n",
       " 0.9353519200083962,\n",
       " 0.9310659884481081,\n",
       " 0.9318415697338298,\n",
       " 0.9345449863828561,\n",
       " 0.9345449863828561,\n",
       " 0.9463227930176338]"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_3[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ave(y_list,weight):\n",
    "    L=len(y_list[0])\n",
    "    y_pred=[]\n",
    "    for i in range(0,L):\n",
    "        data=0\n",
    "        for j in range(0,len(y_list)):\n",
    "            data=data+y_list[j][i]*weight[j]\n",
    "        y_pred.append(data)\n",
    "    return y_pred    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=ave([[1,2,4],[3,3,3]],[0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.0, 2.5, 3.5]"
      ]
     },
     "execution_count": 343,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf1=MLPClassifier((30, 2),solver='lbfgs',alpha=170,early_stopping=False, random_state=SEED)\n",
    "clf2=LogisticRegression(C=0.38486969)\n",
    "\n",
    "score=[]  \n",
    "clf1.fit(X,y)\n",
    "y_1=clf1.predict_proba(X_handout)\n",
    "y_1=[x[1] for x in y_1]\n",
    "\n",
    "\n",
    "clf2.fit(X,y)\n",
    "y_2=clf2.predict_proba(X_handout)\n",
    "y_2=[x[1] for x in y_2]\n",
    "\n",
    "\n",
    "y_list=[y_1,y_2]\n",
    "y_f=ave(y_list,[0.5,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8923751131347766"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "clf2=LogisticRegression(C=0.38486969)\n",
    "np.mean(cross_val_score(clf2,X,y,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "write(y_f,output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16000, 30000)"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
